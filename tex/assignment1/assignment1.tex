\documentclass[11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}

\usepackage{amsmath,amssymb,amsfonts}

\title{Principles of Computer System Design\\Assignment 1}
\author{Kristoffer Søholm\\Sebastian Paaske Tørholm}

\begin{document}
\maketitle

\section{Exercises}
\subsection{Question 1, Fundamental abstractions}
\subsubsection{Model for implementing shared address space}
One could model an address in the shared address space as a 2-tuple of two
elements; the address or identifier of a machine, and the address on the given
machine. This is highly scalable, as each component is separated and each of
the two addresses can be interpreted independently. With suitable encoding,
no limitation is needed on the size of either the machine address or memory
address.

This model requires a naming service to determine what address each machine
has. This address could, for instance, be an IP address.
In its simplest form, the tuple is simply \texttt{(ip-address, memory-address)}.

\subsubsection{Pseudocode for implementation of READ/WRITE}

\begin{verbatim}
def READ((machineaddr, dataaddr)):
    try {
        machine = connect(machineaddr, timeout)
        data = machine.read(dataaddr)
        machine.disconnect()
    } catch(TimeoutException) {
        data = null
    }

    return data
\end{verbatim}

\begin{verbatim}
def WRITE((machineaddr, dataaddr), data):
    try {
        machine = connect(machineaddr, timeout)
        data = machine.write(dataaddr, data)
        machine.disconnect()
        return true
    } catch(TimeoutException) {
        return false
    }
\end{verbatim}

Here, \texttt{connect} is a function that produces a connection object to
communicate with the given machine, and said object has a \texttt{read} and
\texttt{write} method that works locally on that machine. In case of a non-responsive
machine, the connect function times out and recovers by responding with null and false,
for reads, resp. writes.

Pattern matching is used to extract the parts of the address from the full
address (tuple).

\subsubsection{Are READ/WRITE against memory atomic?}
On most architectures, reads and writes of a word size is atomic. Larger 
reads/writes tends to be conducted in software through smaller writes,
without explicit hardware support for atomic large transfer of data.

Most commonly, a write would be expected to be atomic by the programmer using
the service. As such, implementing atomicity would most likely be desired, since
partially written data in many contexts would be considered corrupt.

Atomicity could be achieved using one of the locking mechanisms mentioned
in the lectures. Locking could be done on a per-machine basis, or the
memory space of each machine could be split into regions, for which locks
must be held to perform operations. This could be further expanded to use
shared/exclusive locks and so on.

\subsubsection{Dynamic joins}
Our choice of naming scheme allows new machines to be added simply by giving
them an address in the naming service. Dynamic leaving requires redundancy to
prevent memory locations from becoming unavailable. Replacement of a server
could occur by taking down the old server and assigning the new server with the
old address in the naming service.

\subsection{Question 2, Performance}
\subsubsection{How does concurrency influence latency?}

The latency will be lower, if the overhead of scheduling, work partitioning and
other concurrency related overhead is less than the gain from parallelizing the
computation and vice versa. This will in practice favor larger computations and
datasets, while influencing smaller jobs negatively.

\subsubsection{What is the difference between dallying and batching?}

Batching is the act of performing several related actions simultaneously.
Dallying is the act of postponing an action, in order to later potentially batch
the action together with another related action, or maybe avoid doing it at all.

As an example, we can look at memory mapped files, where data is read from the
disk in batches (pages).
Write requests are dallied by only writing changes to ram, postponing disk
writes until strictly necessary, potentially batching several changes to a page
into one disk write.

\subsubsection{Is caching an example of fast path optimization?}

Caching exploits the fact that more frequently accessed items are more likely
to be in the cache. By this virtue, caching will often improve the common case
and is therefore an example of fast path optimization.

\section{Testing}

The tests have been expanded with tests checking whether or not the relevant
functions\footnote{\texttt{buyBooks}, \texttt{rateBooks}, \texttt{addBooks}
and \texttt{updateEditorPicks}} obey all-or-nothing semantics, by attempting
to do a transaction where some elements would succeed and others should fail.
% XXX: Mangler at opdatere buyBooks så den gør dette.
% XXX: Bør også teste samme ting i updateEditorPicks, men er lidt mere besværligt

\section{Architecture}

\subsection{How does it achieve strong modularity?}
The architecture is strongly modular in the sense that almost all parts can be
replaced or modified without affecting the system as a whole. For example, the
CertainBookstore singleton instance can be made to use a distributed system,
storing data on multiple systems. The protocol between clients and the system
can remain consistent even though the BookStoreHTTPServer needs to change its
protocol, and likewise the protocol can change without affecting either the
client and the server.

As long as good coding practice is used, the same protection should be achieved
in a local JVM. It cannot be enforced, however, as clients in principle can
bypass the proxy and interact directly with the methods of the server.

\subsection{Is there a naming service?}
The closest thing to a naming service is the translation from tags to method
calls in \texttt{BookStoreHTTPMesageHandler}. There is no method for service
discovery, apart from knowing the message tags. This can easily be achieved,
though, having a service for sending the list of available services.

\subsection{Which RPC semantics do we use?}
The architecture uses at-most-once, since the client has no way of knowing
what happens to the server state in the case of a server error or a connection
timeout.

\subsection{Is usage of proxy servers safe?}
You could safely add proxying between the client proxies and the HTTP server
itself. In the current state it's doubtful that this would add better
scalability, however, since all requests still need to go through the HTTP
server one at a time anyway.

Caching could be added to help alleviate this, with appropriate measures taken
to handle invalidation of modified data. Furthermore, if the HTTP server was
rewritten to support batched requests, dallying could be employed by the proxy
servers, allowing them to send larger number of requests with fewer connections.

\subsection{Are there scalability bottlenecks wrt. the number of clients?}
The backend, consisting of a synchronized singleton instance, is the biggest
bottleneck in the current system, as all requests must be handled by it. This
can be alleviated by rewriting the backend as a distributed system, but this
would complicate the design by a decent amount.

\subsection{How would clients experience failures if proxies were used?}
The clients would not necessarily see a difference if proxies were used. If
the proxies emply caching they could mask read errors by simply returning
the cached values, and they could mask certain small errors by transparently
resending requests. This should, however, be done with care, in order to
prevent change of semantics and potential overloading of the backend server.

\end{document}

