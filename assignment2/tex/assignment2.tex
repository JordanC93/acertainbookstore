\documentclass[11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{hyperref}

\usepackage{amsmath,amssymb,amsfonts}

\title{Principles of Computer System Design\\Assignment 2}
\author{Kristoffer Søholm\\Sebastian Paaske Tørholm}

\begin{document}
\maketitle

\section{Exercises}
\subsection{Question 1: Serializability \& Locking}
The dependency graphs for the two schedules are given in \autoref{sched1} and
\autoref{sched2} below:

\begin{figure}[h!]
    \includegraphics{graph1_dot.pdf}
\centering
\caption{Schedule 1}
\label{sched1}
\end{figure}

\begin{figure}[h!]
    \includegraphics{graph2_dot.pdf}
\centering
\caption{Schedule 2}
\label{sched2}
\end{figure}

As we can see, schedule 1 is not conflict serializable, since it contains a
cycle, while schedule 2 is.

Schedule 1 cannot have been generated by strict 2PL, since it is not conflict
serializable. It is possible for schedule 2, however, as shown below:

\begin{verbatim}
T1: s(X) R(X)                             x(Y) W(Y) C r
T2:                           s(Z) R(Z)                  x(X) W(X) x(Y) W(Y) C r
T3:            x(Z) W(Z) C r
\end{verbatim}

Here we use \texttt{s(X)} to denote acquiring the shared lock for \texttt{X},
\texttt{x(X)} for the exclusive lock for \texttt{X}, and \texttt{r} for
releasing all locks in the current transaction.

\subsection{Question 2: Optimistic Concurrency Control}
\subsubsection{Scenario 1}
In this scenario T3 needs to be rolled back because of test 2, since
T2 ends before T3's write phase and $\mathtt{WriteSet}(T_2) \,\cap\,
\mathtt{ReadSet}(T_3) = \{4\}$. Per test 1, T1 doesn't affect T3.

\subsubsection{Scenario 2}
The transaction needs to be rolled back because of test 2 applied on
$(T_1,T_3)$, as $\mathtt{WriteSet}(T_1) \,\cap\, \mathtt{ReadSet}(T_3) =
\{3\}$. There is no conflict between T2 and T3 per test 3.

\subsubsection{Scenario 3}
In this case the transaction succeeds, as we need to use test 2 on both the
pairs $(T_1, T_3)$ and $(T_2, T_3)$, and both times the test succeeds.

\section{Testing}
We have added the two tests described in the assignment. We have not been able
to make them fail on the non-thread safe version, however, as the race
conditions seems to be very hard to trigger for small test sets.

We have added one similar test, which is like the first test, except it tests
\texttt{setEditorPicks}. We generate 200 books and alternate between setting
\texttt{editorPick} on half of them, while running a verifier in a seperate
thread that ensures that only picks from the same half are returned.

\section{Implementation}
Our locking scheme is simply to use a read-write lock around the
\texttt{bookMap}, and modify the methods to take the read- or write lock
as appropriate, and let go of the lock as soon as possible. We use the
built in class \texttt{ReadWriteLock} to achieve this. 

It is very easy to see that this method is correct, but it does not achieve a
very high degree of concurrency, especially as many of the methods need to take
the write lock. Under the assumption that few people buy books compared to how
many browse for books, we get a reasonably high amount of concurrency.

\label{lol}
A slightly better approach would be to implement some form
of segmentation of the books (for example a segment per book), and give each
segment its own read-write lock. Care would then need to be taken to prevent
deadlocks, for example to lock in order of increasing ISBN.

\section{Discussion of Implementation}
\subsection{Is your locking protocol correct?}
Our locking protocol is correct, as it is equivalent to a conservative strict
2PL. Predicate reads work as well, as we lock the entire table.

\subsection{Can your locking protocol lead to deadlocks?}
No, as there is only a single lock.

\subsection{Are there any scalability bottlenecks?}
The scalability bottleneck is that we only have a single lock for the entire
table. This is a problem if there is a high amount of writes compared to
reads. Multiple-granularity locking could be a solution to alleviate this,
as discussed in \autoref{lol}. The simplicity of this solution makes the
correctness obvious, so further improvements should not be made blindly before
actually experiencing perfomance problems.

\subsection{What is the overhead vs. the degree of concurrency}
Our overhead is negligible, as it consists of only a single lock, while
it achieves some concurrency, especially for high amounts of reads. For
more granular locking schemes, the overhead vs the performance gained from
concurrency should be determined by testing.

\end{document}

